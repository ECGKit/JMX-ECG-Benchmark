# -*- coding: utf-8 -*-
"""
This code is used to analyse csv files generated by 'jmx_detector_analysis.py'
and normalise (using a global mean value) and map coefficients which represent
detector performance for temporal jitter(J), missed beats(M), and extra detections(X).
These are combined to give an overall'JMX Benchmark' rating for a detector
which is shown for Einthoven II and Chest strap leads. The individual values
for J, M, and X are also plotted individually for Einthoven II and Chest strap.

"""

import pandas as pd
import numpy as np
import os.path as path
import matplotlib.pyplot as plt

all_detectors=['two_average_detector', 'swt_detector', 'engzee_detector', 'christov_detector', 'hamilton_detector', 'pan_tompkins_detector', 'matched_filter_detector']
all_recording_leads=["einthoven_ii", "chest_strap_V2_V1"] # can be expanded if required
# all_experiments = ["sitting","maths","walking","hand_bike","jogging"] # Needed?
all_categories=["jitter", "missed", "extra"] # 


def mapping_curve():
    # equate mean point to cube root of 0.5 so that if all three parameters are average, when multiplied together we get 50% as an overall result
    for_x_is_1 = 0.5 ** (1. / 3) # i.e cube root of 0.5
    # To use individual parameters for comparison, use parameter^3, again to make 0.5=mean
    
    x = np.array([0.0, 1.0, 6.0, 10.0]) # 'source' input points for piecewise mapping
    # x = np.array([0.0, 1.0, 8.0, 15.0]) # alternative mapping for more detail in lower values.
    y = np.array([1.0, for_x_is_1, 0.2, 0.0]) # 'destination' output points for piecewise mapping
    z = np.polyfit(x, y, 3) # z holds the polynomial coefficients of 3rd order curve fit
    # i.e. z[0] = coeff of x^3, z[1] = coeff of x^2, z[2] = coeff of x, z[3] = constant
    # If piecewise mapping points are changed, check that polynomial approximation
    # curve is smooth and does not dip below zero - move 3rd input point (default 6.0)
    # if required.
    # To test plot 3rd order curve fit (uncomment to plot):
        
    # x=np.linspace(0,10,1001)
    # y=(z[0]*x*x*x)+(z[1]*x*x)+(z[2]*x)+z[3]
    # plt.figure()
    # plt.title('Test plot of 3rd order polynomial mapping curve')
    # plt.plot(x,y, color='darkblue')
    # plt.xlabel("Normalised input parameter value")
    # plt.ylabel("Mapped output parameter value")
    # plt.tick_params(axis='x')
    # plt.tick_params(axis='y')
    # plt.grid(b=None, which='both', axis='both')
    
    return z

def return_globals():
    global_filename ="saved_csv/global_results.csv" # set path to 'global_results.csv'
    if path.exists(global_filename) == True: # Does Global values file exist?
        global_values=pd.read_csv(global_filename, dtype=float, index_col=0)
        Global_jitter_mad=pd.Series.tolist(global_values["Global_jitter_mad"])[0]
        Global_missed_mean=pd.Series.tolist(global_values["Global_missed_mean"])[0]
        Global_extra_mean=pd.Series.tolist(global_values["Global_extra_mean"])[0]
        
    else: # Use default values if no Global file exists
        print()
        print('Using default Global reference mean values')
        print()
        Global_jitter_mad = 2.994091613940169
        Global_missed_mean = 2.761072988147224
        Global_extra_mean = 4.480973175296319
    
    return Global_jitter_mad, Global_missed_mean, Global_extra_mean

def normalise_and_map(param, category):
    # Identifies param type, normalises using appropriate global value, and
    # maps to benchmark value using 'poly' 3rd order polynomial
    global_constants=return_globals()
    poly=mapping_curve()
    # Normalise by dividing by appropriate global reference constant
    if category=='jitter':
        param_norm = param/global_constants[0]
    elif category=='missed':
        param_norm = param/global_constants[1]
    elif category=='extra':
        param_norm = param/global_constants[2]
    if param_norm<=10.0: # Is normalised param less than 10x the global reference?
        x = param_norm    
        param_mapped=(poly[0]*x*x*x)+(poly[1]*x*x)+(poly[2]*x)+poly[3]
    else:
        param_mapped=0.0 # if the input parameter is greater than 10x the global
        # reference, a returned value of 0.0 will signify failure as a detector,
        # and when multiplied, the overall benchmark will also be 0
    
    return param_mapped

def overall_benchmark(record_lead, detector, bench_stats):
    # 'bench_stats' is dictionary
    part_name='_accum_'+record_lead+'_'+detector
    bm=100.0 # set initial value of benchmark - multiply by all three individual values
    for key_name in bench_stats.keys():
        if part_name in key_name:
            #print[column]
            bm=bm*bench_stats.get(key_name)
        
    return bm

def category_benchmarks(record_lead, bench_stats):
    # Allow for both leads?
    jitter_list=[]
    missed_list=[]
    extra_list=[]
    for category in all_categories:
        for detector in all_detectors:
            for key_name in bench_stats.keys():
                if record_lead in key_name:
                    if category in key_name:
                        if detector in key_name:
                            exec(category+'_list.append(100.0*((bench_stats.get(key_name))**3))')
                       
    return jitter_list, missed_list, extra_list
            
def autolabel(rects): # https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html
    """Attach a text label above each bar in *rects*, displaying its height."""
    for rect in rects:
        height = rect.get_height()
        height=int(height)
        ax.annotate('{}'.format(height),
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points vertical offset
                    textcoords="offset points",
                    ha='center', va='bottom')

    
    
#%%
# All detectors and recording leads used for analysis should be used for benchmarking

data_filename ="saved_csv/data_det_lead.csv"  
stats_filename ="saved_csv/det_lead_stats.csv"


bench_data=pd.read_csv(data_filename, dtype=float, index_col=0)
bench_stats=pd.read_csv(stats_filename, dtype=float, index_col=0)

mapped_params={} # dictionary for parameters once they have been mapped

for record_lead in all_recording_leads: # loop for all chosen leads
    BM_array = [] # Create empty list for that record lead's benchmarks
    
    for detector in all_detectors: # loop for all detectors
    
        for category in all_categories:
            if category == 'jitter':
                name_end='_mad'
            else:
                name_end='_mean'
            # Now generate all benchmarking values for all parameters
            name=category+'_accum_'+record_lead+'_'+detector+name_end
            name_val=pd.Series.tolist(bench_stats[name])[0]
            #exec('bench_'+name+' = normalise_and_map(name_val, category)')
            mapped_params[name]=normalise_and_map(name_val, category)
    
        detector_overall_BM=overall_benchmark(record_lead, detector, mapped_params)
        BM_array.append(detector_overall_BM)
          
    if record_lead=='einthoven_ii':
        BM_data_einthoven_ii=BM_array
    elif record_lead=='chest_strap_V2_V1':
        BM_data_chest_strap_V2_V1=BM_array
        

BM_einth_jitter, BM_einth_missed, BM_einth_extra = category_benchmarks('einthoven_ii', mapped_params)
BM_chest_jitter, BM_chest_missed, BM_chest_extra = category_benchmarks('chest_strap_V2_V1', mapped_params)      
    
# Now have named variables and values as saved

#%% SET OVERALL PARAMETERS FOR PLOTS:

plt.rcParams['figure.figsize'] = [19.2, 10.8]
plt.rcParams['figure.dpi'] = 100 # Make = 100 for 1920 x 1080 HD video size


plt.ion() # enables interactive mode (keep plots visible until closed)

#%% PLOT OF OVERALL BENCHMARKS FOR EINTH AND CHEST

fig, ax = plt.subplots()
# _tester_utils.det_fullnames = ['Elgendi et al', 'Matched Filter', 'Kalidas and Tamil', 'Engzee Mod', 'Christov', 'Hamilton', 'Pan and Tompkins']
# use 'all_detectors'
x_pos = np.arange(len(all_detectors))

width = 0.4 # set width of bars

ax.yaxis.grid(zorder=0) # Plot grid behind bars for clarity
rects1 = ax.bar(x_pos, BM_data_einthoven_ii, width, alpha=1.0, zorder=3, capsize=10)
rects2 = ax.bar(x_pos+width, BM_data_chest_strap_V2_V1, width, alpha=1.0, zorder=3, capsize=10)
ax.set_ylim([0,110.0])
y_label='JMX Benchmark'
ax.set_ylabel(y_label, fontsize=12.5)
ax.set_xlabel('Detector', fontsize=12.5)
ax.set_xticks(x_pos + width / 2)
ax.set_xticklabels(all_detectors, fontsize=10)
legend1='Einthoven II'
legend2='Chest strap'
ax.legend((rects1[0], rects2[0]), (legend1, legend2), loc='upper left')
ax.set_title('JMX Benchmark - EinthovenII / Chest strap', fontsize=15)

plt.tight_layout()

# Add values to the top of bars
autolabel(rects1)
autolabel(rects2)

#%% PLOTS OF ALL 3 FACTORS - EINTHOVEN

fig, ax = plt.subplots()

x_pos = np.arange(len(all_detectors))

width = 0.25 # set width of bars

ax.yaxis.grid(zorder=0) # Plot grid behind bars for clarity
rects1 = ax.bar(x_pos-width, BM_einth_jitter, width, alpha=1.0, zorder=3, capsize=10)
rects2 = ax.bar(x_pos, BM_einth_missed, width, alpha=1.0, zorder=3, capsize=10)
rects3 = ax.bar(x_pos+width, BM_einth_extra, width, alpha=1.0, zorder=3, capsize=10)

ax.set_ylim([0,110.0])
y_label='JMX Benchmark'
ax.set_ylabel(y_label, fontsize=12.5)
ax.set_xlabel('Detector', fontsize=12.5)
ax.set_xticks(x_pos)
ax.set_xticklabels(all_detectors, fontsize=10)
legend1='Jitter_MAD'
legend2='Missed beats'
legend3='Extra detections'
ax.legend((rects1[0], rects2[0], rects3[0]), (legend1, legend2, legend3), loc='upper left')
ax.set_title('JMX Benchmark - Einthoven II individual', fontsize=15)
 
plt.tight_layout()

# Add values to the top of bars
autolabel(rects1)
autolabel(rects2) 
autolabel(rects3)  

            
#%% PLOTS OF ALL 3 FACTORS - CHEST

fig, ax = plt.subplots()

x_pos = np.arange(len(all_detectors))

width = 0.25 # set width of bars

ax.yaxis.grid(zorder=0) # Plot grid behind bars for clarity
rects1 = ax.bar(x_pos-width, BM_chest_jitter, width, alpha=1.0, zorder=3, capsize=10)
rects2 = ax.bar(x_pos, BM_chest_missed, width, alpha=1.0, zorder=3, capsize=10)
rects3 = ax.bar(x_pos+width, BM_chest_extra, width, alpha=1.0, zorder=3, capsize=10)

ax.set_ylim([0,110.0])
y_label='JMX Benchmark'
ax.set_ylabel(y_label, fontsize=12.5)
ax.set_xlabel('Detector', fontsize=12.5)
ax.set_xticks(x_pos)
ax.set_xticklabels(all_detectors, fontsize=10)
legend1='Jitter_MAD'
legend2='Missed beats'
legend3='Extra detections'
ax.legend((rects1[0], rects2[0], rects3[0]), (legend1, legend2, legend3), loc='upper left')
ax.set_title('JMX Benchmark - Chest_strap_V2_V1 individual', fontsize=15)

plt.tight_layout()

# Add values to the top of bars
autolabel(rects1)
autolabel(rects2) 
autolabel(rects3)        

plt.ioff()
plt.show()
            
       
